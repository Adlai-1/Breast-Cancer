{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = 'C:/Users/David/Desktop/AI_Project/Images/Train Images'\n",
    "test_dir ='C:/Users/David/Desktop/AI_Project/Images/Test Images'\n",
    "valid_dir = test_dir ='C:/Users/David/Desktop/AI_Project/Images/Validation Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64532 images belonging to 2 classes.\n",
      "Found 27657 images belonging to 2 classes.\n",
      "Found 27657 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Generating our image data file....,target_size=(224,224)\n",
    "train_dataset = ImageDataGenerator().flow_from_directory(train_dir,target_size=(80,80),classes=['non-pCR','pCr'],batch_size=100)\n",
    "test_dataset = ImageDataGenerator().flow_from_directory(test_dir,target_size=(80,80),classes=['non-pCR','pCr'],batch_size=100)\n",
    "valid_dataset = ImageDataGenerator().flow_from_directory(valid_dir,target_size=(80,80),classes=['non-pCR','pCr'],batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data , label = next(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.asarray(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "da.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(3,80,80)),\n",
    "    Dense(128,activation='relu'),\n",
    "    Dense(128,activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(32,activation='relu'),\n",
    "    Dense(32,activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(16,activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(2,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 88s 875ms/step - loss: 95.4849 - acc: 0.5691 - val_loss: 12.5381 - val_acc: 0.3295\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 83s 832ms/step - loss: 15.4321 - acc: 0.5531 - val_loss: 18.8579 - val_acc: 0.5000\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 83s 834ms/step - loss: 14.1904 - acc: 0.5618 - val_loss: 9.8658 - val_acc: 0.6705\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 84s 839ms/step - loss: 17.9709 - acc: 0.5576 - val_loss: 10.6184 - val_acc: 0.5000\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 83s 833ms/step - loss: 6.7334 - acc: 0.5618 - val_loss: 4.1677 - val_acc: 0.3278\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 83s 835ms/step - loss: 2.5729 - acc: 0.5674 - val_loss: 1.3821 - val_acc: 0.6723\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 84s 839ms/step - loss: 2.0935 - acc: 0.5786 - val_loss: 4.8027 - val_acc: 0.5000\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 83s 829ms/step - loss: 1.0672 - acc: 0.6084 - val_loss: 0.6272 - val_acc: 0.6751\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 0.6270 - acc: 0.6704 - val_loss: 0.6116 - val_acc: 0.6847\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 0.6151 - acc: 0.6772 - val_loss: 0.6056 - val_acc: 0.6844\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 0.6184 - acc: 0.6754 - val_loss: 0.5973 - val_acc: 0.6917\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.6276 - acc: 0.6633 - val_loss: 0.6722 - val_acc: 0.6730\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 33s 330ms/step - loss: 0.6710 - acc: 0.6448 - val_loss: 0.5883 - val_acc: 0.6958\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.6399 - acc: 0.6636 - val_loss: 0.6681 - val_acc: 0.6731\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.6336 - acc: 0.6676 - val_loss: 0.5997 - val_acc: 0.7123\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 0.6048 - acc: 0.6860 - val_loss: 0.5877 - val_acc: 0.7193\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.6118 - acc: 0.6830 - val_loss: 0.5956 - val_acc: 0.6816\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 32s 325ms/step - loss: 0.6215 - acc: 0.6740 - val_loss: 0.5814 - val_acc: 0.6917\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 4.2067 - acc: 0.6215 - val_loss: 8.7700 - val_acc: 0.5000\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 3.2097 - acc: 0.5879 - val_loss: 0.6468 - val_acc: 0.6708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed387c8c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_dataset,validation_data=valid_dataset,epochs=20,steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = next(train_dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 329us/sample - loss: 0.6370 - acc: 0.7000\n",
      "0.6370293664932251 0.7\n"
     ]
    }
   ],
   "source": [
    "#Evaluating the Loss and Accuracy Generated by the model after testing.....\n",
    "vloss , vacc = model.evaluate(data,label)\n",
    "print(vloss,vacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 19200)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               2457728   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 2,479,986\n",
      "Trainable params: 2,479,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summary of the Model...\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Trained Model.....\n",
    "model.save(\"Pcr and non-Pcr Breast Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data , test_label = next(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = model.predict([test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Predict[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
